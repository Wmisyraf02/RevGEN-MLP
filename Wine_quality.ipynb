{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425fe94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from RevGEN_MLP import RevGEN_MLP  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.ensemble import IsolationForest,RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5540e9",
   "metadata": {},
   "source": [
    "# RevGEN-MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce0068f",
   "metadata": {},
   "source": [
    "## Loading and Preparing Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b18b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"wine+quality\\\\winequality-white.csv\", sep=\";\") # Insert path to dataset here\n",
    "df['good'] = (df['quality'] >= 7).astype(int)\n",
    "X = df.drop(['quality', 'good'], axis=1)\n",
    "y = df['good']\n",
    "\n",
    "column_names = X.columns\n",
    "\n",
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "# One-hot encode labels\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_encoded = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_encoded =encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Scale features \n",
    "ANN_scaler = StandardScaler()\n",
    "X_train_scaled = ANN_scaler.fit_transform(X_train)\n",
    "X_test_scaled = ANN_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68afcd7c",
   "metadata": {},
   "source": [
    "## Training RevGEN-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8044605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layer = 3\n",
    "num_epochs = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc6dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Initialize model\n",
    "model = RevGEN_MLP(\n",
    "    n_layers=num_layer,\n",
    "    x=X_train_scaled[0].reshape(-1, 1),\n",
    "    y_actual=y_train_encoded[0].reshape(-1, 1),\n",
    "    epochs=num_epochs,\n",
    "    loss_function=\"cross_entropy\"\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    loss_epoch = 0\n",
    "    correct_train = 0\n",
    "\n",
    "    # Shuffle training indices\n",
    "    indices = np.random.permutation(X_train_scaled.shape[0])\n",
    "\n",
    "    for i in indices:\n",
    "        x_sample = X_train_scaled[i].reshape(-1, 1)\n",
    "        y_sample = y_train_encoded[i].reshape(-1, 1)\n",
    "\n",
    "        # Train and accumulate loss\n",
    "        model.train(input=x_sample, target=y_sample)\n",
    "        loss_epoch += model.loss_fn(input=x_sample, target=y_sample)\n",
    "\n",
    "        # Predict and count correct predictions\n",
    "        pred = model.forward(x_sample)\n",
    "        if np.argmax(pred[:2]) == np.argmax(y_sample):\n",
    "            correct_train += 1\n",
    "\n",
    "    # Compute average training metrics\n",
    "    avg_train_loss = loss_epoch / X_train_scaled.shape[0]\n",
    "    train_accuracy = correct_train / X_train_scaled.shape[0]\n",
    "\n",
    "    # Evaluate on test set every 10 epochs\n",
    "    if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "        correct_test = 0\n",
    "        test_loss_epoch = 0\n",
    "\n",
    "        for i in range(X_test_scaled.shape[0]):\n",
    "            x_sample = X_test_scaled[i].reshape(-1, 1)\n",
    "            y_sample = y_test_encoded[i].reshape(-1, 1)\n",
    "\n",
    "            pred = model.forward(x_sample)\n",
    "            if np.argmax(pred[:2]) == np.argmax(y_sample):\n",
    "                correct_test += 1\n",
    "\n",
    "            test_loss_epoch += model.loss_fn(input=x_sample, target=y_sample)\n",
    "\n",
    "        avg_test_loss = test_loss_epoch / X_test_scaled.shape[0]\n",
    "        test_accuracy = correct_test / X_test_scaled.shape[0]\n",
    "\n",
    "        print(f\"Epoch {epoch:3d} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy * 100:.2f}% | \"\n",
    "              f\"Test Loss: {avg_test_loss:.4f} | Test Acc: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d4da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "y_preds = []\n",
    "y_true = []\n",
    "\n",
    "for i in range(X_test_scaled.shape[0]):\n",
    "    x_sample = X_test_scaled[i].reshape(-1, 1)\n",
    "    y_sample = y_test_encoded[i].reshape(-1, 1)\n",
    "\n",
    "    pred = model.forward(x_sample)\n",
    "    pred_class = np.argmax(pred[0:2])\n",
    "    true_class = np.argmax(y_sample)\n",
    "\n",
    "    y_preds.append(pred_class)\n",
    "    y_true.append(true_class)\n",
    "\n",
    "    if pred_class == true_class:\n",
    "        correct += 1\n",
    "\n",
    "x_sample = X_test_scaled[0].reshape(-1, 1)\n",
    "pred = model.forward(x_sample)\n",
    "\n",
    "\n",
    "test_accuracy = correct / X_test_scaled.shape[0]\n",
    "precision = precision_score(y_true, y_preds, average='macro', zero_division=0)\n",
    "recall = recall_score(y_true, y_preds, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_true, y_preds, average='macro', zero_division=0)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Precision:     {precision * 100:.2f}%\")\n",
    "print(f\"Recall:        {recall * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e30fc9c",
   "metadata": {},
   "source": [
    "## Invertibility Check\n",
    "\n",
    "Small reconstruction errors close to zero are expected due to floating-point precision limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a82a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample = X_test_scaled[0].reshape(-1, 1)\n",
    "\n",
    "# Unscale \n",
    "x_sample_unscaled = ANN_scaler.inverse_transform(x_sample.reshape(1, -1))\n",
    "print(\"Original Sample:\", x_sample_unscaled)\n",
    "\n",
    "# Forward pass\n",
    "pred = model.forward(x_sample)\n",
    "print(\"\\nOutput (Classes):\", pred[0:2].ravel())\n",
    "print(\"Output (Latent Variable):\", pred[2:].ravel())\n",
    "# Reconstruct\n",
    "reconstructed_sample = model.reverse(pred)\n",
    "\n",
    "# Unscale reconstruction\n",
    "reconstructed_sample_unscaled = ANN_scaler.inverse_transform(\n",
    "    reconstructed_sample.reshape(1, -1)\n",
    ")\n",
    "print(\"\\nReconstructed Sample:\", reconstructed_sample_unscaled.ravel())\n",
    "\n",
    "mse_scaled = np.mean((x_sample - reconstructed_sample)**2)\n",
    "mse_unscaled = np.mean((x_sample_unscaled - reconstructed_sample_unscaled)**2)\n",
    "print(\"\\nMSE Error (Scaled Data): \", mse_scaled)\n",
    "print(\"MSE Error (Unscaled Data): \", mse_unscaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeab7550",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = IsolationForest(random_state=42).fit(X)\n",
    "\n",
    "\n",
    "scores = detector.decision_function(X)\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(scores, bins=50)\n",
    "threshold = np.percentile(scores, 5)\n",
    "plt.axvline(threshold, color='red', linestyle='--', label='5th percentile threshold')\n",
    "\n",
    "# Add label\n",
    "plt.text(threshold, plt.ylim()[1]*0.9, '5% threshold', color='red', rotation=90, va='top', ha='right')\n",
    "\n",
    "plt.title(\"Isolation Forest Anomaly Scores - White Wine Quality\")\n",
    "plt.xlabel(\"Anomaly Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec409fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_with_epsilon(model,epsilon):\n",
    "    pred_classes = []\n",
    "    inputs = []\n",
    "    original_inputs = []\n",
    "    original_classes = []\n",
    "    original_prob = []\n",
    "    pred_probability = []\n",
    "\n",
    "    for test,truth in zip(X_test_scaled,y_test_encoded):\n",
    "        x_sample = test.reshape(-1, 1)\n",
    "        pred = model.forward(x_sample)\n",
    "\n",
    "        class_probs = pred[0:2].ravel()\n",
    "        max_prob = np.max(class_probs)\n",
    "        if np.argmax(pred[:2]) == np.argmax(truth):\n",
    "            if max_prob >= 0.8:\n",
    "                original_prob.append(max_prob)\n",
    "                pred_class = np.argmax(class_probs)\n",
    "                original_inputs.append(ANN_scaler.inverse_transform(x_sample.reshape(1, -1))[0])\n",
    "                original_classes.append(pred_class)\n",
    "                vector = pred.copy()\n",
    "                vector[2:] = vector[2:] + epsilon\n",
    "                \n",
    "                new_input = model.reverse(input=vector)\n",
    "                new_pred = model.forward(new_input)\n",
    "                max_prob = np.max(new_pred[0:2])\n",
    "                pred_probability.append(max_prob)\n",
    "                new_pred_class = np.argmax(new_pred[0:2])\n",
    "\n",
    "                new_input_unscaled = ANN_scaler.inverse_transform(new_input.reshape(1, -1))[0]\n",
    "\n",
    "                pred_classes.append(new_pred_class)\n",
    "                inputs.append(new_input_unscaled)\n",
    "                \n",
    "    # Build DataFrame\n",
    "    data = {col: [] for col in column_names}\n",
    "    data[\"Class\"] = []\n",
    "    data[\"Probability\"] = []\n",
    "\n",
    "    for sample in inputs:\n",
    "        for i, col in enumerate(column_names):\n",
    "            data[col].append(sample[i])\n",
    "\n",
    "    for cls in pred_classes:\n",
    "        data[\"Class\"].append(cls)\n",
    "\n",
    "    for prob in pred_probability:\n",
    "        data[\"Probability\"].append(prob * 100)\n",
    "\n",
    "    generated_df = pd.DataFrame(data=data)\n",
    "    return generated_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d665de",
   "metadata": {},
   "source": [
    "### Anomaly Score Threshold\n",
    "\n",
    "The following code decides the anomaly score threshold used to guide generation. The first threshold represents moderately anomalous data whereas the second threshold represents extremely anomalous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f29b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_1 = np.percentile(scores,5)\n",
    "threshold_2 = -0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exponents = np.linspace(-12, -2 , 600)\n",
    "positive_epsilons = 10 ** exponents\n",
    "negative_epsilons = -positive_epsilons\n",
    "epsilons = np.sort(np.concatenate([negative_epsilons, positive_epsilons]))\n",
    "\n",
    "threshold = threshold_2 # Change threshold as needed\n",
    "results = []\n",
    "\n",
    "for epsilon in epsilons:\n",
    "    generated_df = generate_data_with_epsilon(model, epsilon)\n",
    "    anomaly_score_results = []\n",
    "\n",
    "    for cls in generated_df[\"Class\"].unique():\n",
    "        subset = generated_df[generated_df[\"Class\"] == cls]\n",
    "        features = subset.drop(columns=[\"Class\", \"Probability\"]).to_numpy()\n",
    "        score = detector.decision_function(features)\n",
    "\n",
    "        anomaly_score_results.append({\n",
    "            \"Class\": cls,\n",
    "            \"Score\": score.mean()\n",
    "        })\n",
    "\n",
    "    scored_df = pd.DataFrame(anomaly_score_results)\n",
    "    mean_score_by_class = scored_df.set_index(\"Class\")[\"Score\"]\n",
    "    below_threshold = mean_score_by_class[mean_score_by_class < threshold].to_dict()\n",
    "\n",
    "    results.append({\n",
    "        \"epsilon\": epsilon,\n",
    "        \"mean_score\": mean_score_by_class.to_dict(),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d54d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names = []\n",
    "for r in results:\n",
    "    for cls in r[\"mean_score\"]:\n",
    "        if cls not in class_names:\n",
    "            class_names.append(cls)\n",
    "class_names.sort()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cls in class_names:\n",
    "    eps = []\n",
    "    overlaps = []\n",
    "    for r in results:\n",
    "        eps.append(r[\"epsilon\"])\n",
    "        overlaps.append(r[\"mean_score\"].get(cls))\n",
    "    plt.plot(eps, overlaps, marker='o', label=f'Class {cls}')\n",
    "\n",
    "\n",
    "# Threshold line\n",
    "plt.axhline(y=threshold, color='red', linestyle='--', label=f'Threshold ({threshold})')\n",
    "\n",
    "# Log scale on x-axis\n",
    "\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Mean Anomaly Score (Isolation Forest)\")\n",
    "\n",
    "plt.title(\"Mean Anomaly Score (Isolation Forest) vs. Epsilon (Alpha = 1)\")\n",
    "plt.legend()\n",
    "plt.xscale(\"symlog\")\n",
    "plt.grid(True, which=\"both\", ls=\"--\", linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6528d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epsilons = {}\n",
    "best_eps_overall = None\n",
    "max_abs_eps = 0  # Track largest absolute epsilon\n",
    "\n",
    "for cls in class_names:\n",
    "    best_pos_eps = None\n",
    "    best_neg_eps = None\n",
    "    best_pos_diff = float('inf')\n",
    "    best_neg_diff = float('inf')\n",
    "\n",
    "    for r in results:\n",
    "        score = r[\"mean_score\"].get(cls)\n",
    "        eps = r[\"epsilon\"]\n",
    "\n",
    "        if score is not None and score < threshold:\n",
    "            diff = threshold - score\n",
    "\n",
    "            if eps > 0 and diff < best_pos_diff:\n",
    "                best_pos_diff = diff\n",
    "                best_pos_eps = eps\n",
    "\n",
    "            elif eps < 0 and diff < best_neg_diff:\n",
    "                best_neg_diff = diff\n",
    "                best_neg_eps = eps\n",
    "\n",
    "    best_epsilons[cls] = {\n",
    "        \"best_positive\": best_pos_eps,\n",
    "        \"best_negative\": best_neg_eps\n",
    "    }\n",
    "\n",
    "    for eps in [best_pos_eps, best_neg_eps]:\n",
    "        if eps is not None and abs(eps) > max_abs_eps:\n",
    "            max_abs_eps = abs(eps)\n",
    "            best_eps_overall = eps\n",
    "\n",
    "for cls, eps_dict in best_epsilons.items():\n",
    "    print(f\"Class {cls}:\")\n",
    "    print(f\"  Best positive epsilon: {eps_dict['best_positive']}\")\n",
    "    print(f\"  Best negative epsilon: {eps_dict['best_negative']}\")\n",
    "\n",
    "print(f\"\\nBest overall epsilon across all classes: {best_eps_overall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0983d68b",
   "metadata": {},
   "source": [
    "## Generated Confidently Classified Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34059fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = max_abs_eps\n",
    "\n",
    "\n",
    "pred_classes = []\n",
    "inputs = []\n",
    "original_inputs = []\n",
    "original_classes = []\n",
    "original_prob = []\n",
    "pred_probability = []\n",
    "\n",
    "for test,truth in zip(X_test_scaled,y_test_encoded):\n",
    "    x_sample = test.reshape(-1, 1)\n",
    "    pred = model.forward(x_sample)\n",
    "\n",
    "    class_probs = pred[0:2].ravel()\n",
    "    max_prob = np.max(class_probs)\n",
    "    if np.argmax(pred[:2]) == np.argmax(truth):\n",
    "        if max_prob >= 0.8:\n",
    "            original_prob.append(max_prob)\n",
    "            pred_class = np.argmax(class_probs)\n",
    "            original_inputs.append(ANN_scaler.inverse_transform(x_sample.reshape(1, -1))[0])\n",
    "            original_classes.append(pred_class)\n",
    "\n",
    "            vector_neg_epsilon = pred.copy()\n",
    "            vector_neg_epsilon[2:] = vector_neg_epsilon[2:] - epsilon\n",
    "\n",
    "            # Revese pass for when epsilon is substracted to latent variables\n",
    "            new_input_neg = model.reverse(input=vector_neg_epsilon)\n",
    "            new_pred = model.forward(new_input_neg)\n",
    "            max_prob = np.max(new_pred[0:2])\n",
    "            pred_probability.append(max_prob)\n",
    "            new_pred_class_neg = np.argmax(new_pred[0:2])\n",
    "\n",
    "            vector_pos_epsilon = pred.copy()\n",
    "            vector_pos_epsilon[2:] = vector_pos_epsilon[2:] + epsilon\n",
    "\n",
    "            # Revese pass for when epsilon is added to latent variables\n",
    "            new_input_pos = model.reverse(input=vector_pos_epsilon)\n",
    "            new_pred = model.forward(new_input_pos)\n",
    "            max_prob_pos = np.max(new_pred[0:2])\n",
    "            pred_probability.append(max_prob_pos)\n",
    "            new_pred_class_pos = np.argmax(new_pred[0:2])\n",
    "\n",
    "            new_input_unscaled_pos = ANN_scaler.inverse_transform(new_input_pos.reshape(1, -1))[0]\n",
    "            new_input_unscaled_neg = ANN_scaler.inverse_transform(new_input_neg.reshape(1, -1))[0]\n",
    "\n",
    "            pred_classes.append(new_pred_class_pos)\n",
    "            inputs.append(new_input_unscaled_pos)\n",
    "\n",
    "            pred_classes.append(new_pred_class_neg)\n",
    "            inputs.append(new_input_unscaled_neg)\n",
    "\n",
    "\n",
    "\n",
    "data = {col: [] for col in column_names}\n",
    "data[\"Class\"] = []\n",
    "data[\"Probability\"] = []\n",
    "\n",
    "for sample in inputs:\n",
    "    for i, col in enumerate(column_names):\n",
    "        data[col].append(sample[i])\n",
    "\n",
    "for cls in pred_classes:\n",
    "    data[\"Class\"].append(cls)\n",
    "\n",
    "for prob in pred_probability:\n",
    "    data[\"Probability\"].append(prob * 100)\n",
    "\n",
    "generated_df = pd.DataFrame(data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38259137",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_df = generated_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e09abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list = detector.predict(inputs).tolist()\n",
    "\n",
    "\n",
    "anomalies = prediction_list.count(-1) / len(inputs)\n",
    "print(f\"Anomaly rate: {anomalies:.2%}\")\n",
    "\n",
    "\n",
    "inputs = np.array(inputs)\n",
    "predictions = np.array(prediction_list)\n",
    "\n",
    "anomalous_inputs = inputs[predictions == -1]\n",
    "\n",
    "generated_anomalies = pd.DataFrame(anomalous_inputs, columns=column_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e422bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_anomalies=generated_anomalies.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221965b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list = detector.predict(X).tolist()\n",
    "\n",
    "anomalies = prediction_list.count(-1)/len(X)\n",
    "\n",
    "print(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e309d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8fb022",
   "metadata": {},
   "source": [
    "# Transferability Of Confidently Clasified Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f54310",
   "metadata": {},
   "source": [
    "## Testing Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8971402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_threshold = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94641e46",
   "metadata": {},
   "source": [
    "## Randomn Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da0b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RF_model = RandomForestClassifier(n_estimators=200,random_state=42)\n",
    "RF_model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = RF_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "test_precision = precision_score(y_test, y_pred,average=\"macro\")\n",
    "test_recall = recall_score(y_test, y_pred,average=\"macro\")\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Test Precision:\", test_precision)\n",
    "print(\"Test Recall:\", test_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c7197",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "probs_all = RF_model.predict_proba(generated_anomalies.values)\n",
    "\n",
    "max_probs = np.max(probs_all, axis=1)\n",
    "pred_classes = np.argmax(probs_all, axis=1)\n",
    "\n",
    "\n",
    "mask = max_probs >= confidence_threshold\n",
    "RF_anomalies_list = generated_anomalies.values[mask]\n",
    "max_prob_rf = pred_classes[mask]\n",
    "high_confidence_count = np.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fae21ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness = high_confidence_count/len(generated_anomalies.values)\n",
    "print(robustness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_df = pd.DataFrame(RF_anomalies_list, columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70271011",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(RF_anomalies_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa99401",
   "metadata": {},
   "source": [
    "## Testing On Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e6a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Model architecture\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "test_model = SimpleNet(input_dim=X_train_tensor.shape[1])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(test_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 440\n",
    "for epoch in range(num_epochs):\n",
    "    test_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = test_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "        test_model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = test_model(X_test_tensor)\n",
    "            preds = torch.argmax(test_outputs, dim=1)\n",
    "            acc = accuracy_score(y_test_tensor, preds)\n",
    "            print(f\"Epoch {epoch:3d} | Loss: {loss.item():.4f} | Test Accuracy: {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece01b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_model.eval()\n",
    "correct = 0\n",
    "y_preds = []\n",
    "y_true = []\n",
    "\n",
    "for i in range(X_test_scaled.shape[0]):\n",
    "    x_sample = torch.tensor(X_test_scaled[i].reshape(1, -1), dtype=torch.float32)\n",
    "    y_sample = y_test_encoded[i].reshape(-1)  # Assuming one-hot encoded\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = test_model(x_sample)\n",
    "        probs = torch.softmax(logits, dim=1).numpy().flatten()\n",
    "        pred_class = np.argmax(probs)\n",
    "        true_class = np.argmax(y_sample)\n",
    "\n",
    "    y_preds.append(pred_class)\n",
    "    y_true.append(true_class)\n",
    "\n",
    "    if pred_class == true_class:\n",
    "        correct += 1\n",
    "\n",
    "\n",
    "x_sample = torch.tensor(X_test_scaled[0].reshape(1, -1), dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    pred = test_model(x_sample)\n",
    "\n",
    "\n",
    "test_accuracy = correct / len(X_test_scaled)\n",
    "precision = precision_score(y_true, y_preds, average='macro', zero_division=0)\n",
    "recall = recall_score(y_true, y_preds, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_true, y_preds, average='macro', zero_division=0)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Precision:     {precision * 100:.2f}%\")\n",
    "print(f\"Recall:        {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score:      {f1 * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MLP_anomalies_list = []\n",
    "high_confidence_count = 0\n",
    "test = []\n",
    "scaled_anomalous_inputs = ANN_scaler.transform(generated_anomalies.values)\n",
    "\n",
    "\n",
    "test_model.eval()\n",
    "\n",
    "for x in scaled_anomalous_inputs:\n",
    "    x_tensor = torch.tensor(x.reshape(1, -1), dtype=torch.float32)  # shape: [1, input_dim]\n",
    "    with torch.no_grad():\n",
    "        logits = test_model(x_tensor)  # shape: [1, 2]\n",
    "        probs = torch.softmax(logits, dim=1).numpy().flatten()  # convert to numpy array\n",
    "        max_prob = np.max(probs)\n",
    "\n",
    "    if max_prob >= confidence_threshold:\n",
    "        high_confidence_count += 1\n",
    "        MLP_anomalies_list.append(x)\n",
    "        if np.argmax(probs) ==1:\n",
    "            test.append(x)\n",
    "\n",
    "\n",
    "MLP_anomalies_list = ANN_scaler.inverse_transform(MLP_anomalies_list)\n",
    "\n",
    "\n",
    "robustness = high_confidence_count / len(generated_anomalies.values)\n",
    "print(f\"Robustness: {robustness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aaebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(MLP_anomalies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe8fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_df = pd.DataFrame(MLP_anomalies_list, columns = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3bf258",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e10d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n = 5\n",
    "neigh = KNeighborsClassifier(n_neighbors=n)\n",
    "neigh.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = neigh.predict(X_test_scaled)\n",
    "\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "test_precision = precision_score(y_test, y_pred,average=\"macro\")\n",
    "test_recall = recall_score(y_test, y_pred,average=\"macro\")\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Test Precision:\", test_precision)\n",
    "print(\"Test Recall:\", test_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7857de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_anomalies_list = []\n",
    "high_confidence_count = 0\n",
    "\n",
    "scaled_anomalous_inputs = ANN_scaler.transform(generated_anomalies.values)\n",
    "\n",
    "for x in scaled_anomalous_inputs:\n",
    "    probs = neigh.predict_proba(x.reshape(1, -1))  \n",
    "    max_prob = np.max(probs)                       \n",
    "\n",
    "    if max_prob >= confidence_threshold:\n",
    "        high_confidence_count += 1\n",
    "        KNN_anomalies_list.append(x)\n",
    "\n",
    "robustness = high_confidence_count / len(scaled_anomalous_inputs)\n",
    "KNN_anomalies_list = ANN_scaler.inverse_transform(KNN_anomalies_list)\n",
    "print(robustness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(KNN_anomalies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0fd5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn_df = pd.DataFrame(KNN_anomalies_list, columns = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25b6696",
   "metadata": {},
   "source": [
    "## Checking Shared Vulnerabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d543464",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = column_names.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd4246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Drop duplicates in each DataFrame\n",
    "df_rf = RF_df.drop_duplicates()\n",
    "df_knn = knn_df.drop_duplicates()\n",
    "df_nn = MLP_df.drop_duplicates()\n",
    "\n",
    "# Merge on all columns to find common rows\n",
    "common_rows = df_rf.merge(df_knn, how='inner').merge(df_nn, how='inner')\n",
    "\n",
    "print(\"Number of common rows:\", len(common_rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a9152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy array if needed\n",
    "inputs = common_rows.values\n",
    "\n",
    "# Predict with both models\n",
    "rf_preds = RF_model.predict(inputs)\n",
    "knn_preds = neigh.predict(inputs)\n",
    "\n",
    "# Find indices where class == 1\n",
    "rf_class1_indices = np.where(rf_preds == 1)[0]\n",
    "knn_class1_indices = np.where(knn_preds == 1)[0]\n",
    "\n",
    "# Extract corresponding samples\n",
    "rf_class1_samples = inputs[rf_class1_indices]\n",
    "knn_class1_samples = inputs[knn_class1_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75e8d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d3827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where any feature column has a negative value\n",
    "negative_rows = common_rows[feature_names][(common_rows[feature_names] < 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f263eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e58bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_rows.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b1a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_rows[feature_names].iloc[14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4500d90",
   "metadata": {},
   "source": [
    "## Example of Anomalous Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row = negative_rows.iloc[1]  \n",
    "print(\"Input row (original scale):\")\n",
    "print(sample_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_row = common_rows.iloc[14]  # You can change the index if needed\n",
    "\n",
    "scaled_sample = ANN_scaler.transform(sample_row.values.reshape(1, -1))\n",
    "\n",
    "x_tensor = torch.tensor(scaled_sample, dtype=torch.float32)\n",
    "test_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = test_model(x_tensor)  \n",
    "    probs = torch.softmax(logits, dim=1).numpy().flatten()\n",
    "    max_prob = np.max(probs)\n",
    "    predicted_class = np.argmax(probs)\n",
    "print(\"Neural Network Model\")\n",
    "print(\"Probability of Low Quality:\", probs[0]*100,\"%\")\n",
    "print(\"Probability of Hih Quality Quality:\", probs[1]*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = neigh.predict_proba(sample_row.values.reshape(1,-1))\n",
    "print(\"K-NN Model (K = 5)\")\n",
    "print(\"Probability of Low Quality:\", probs[0][0]*100,\"%\")\n",
    "print(\"Probability of Hih Quality Quality:\", probs[0][1]*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def6fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = RF_model.predict_proba(sample_row.values.reshape(1,-1))\n",
    "print(\"Random Forest Model\")\n",
    "print(\"Probability of Low Quality:\", probs[0][0]*100,\"%\")\n",
    "print(\"Probability of Hih Quality Quality:\", probs[0][1]*100,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
